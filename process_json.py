import requests
import re

# è·å–è¿œç¨‹æ•°æ®
url = 'https://raw.githubusercontent.com/yoursmile66/TVBox/main/XC.json'
response = requests.get(url)

# æ‰“å°å“åº”çŠ¶æ€ç å’Œå†…å®¹
print(f"å“åº”çŠ¶æ€ç : {response.status_code}")

if response.status_code == 200 and response.text.strip():
    # è·å–å“åº”æ–‡æœ¬
    text = response.text

    # åˆ é™¤åŒ…å«ç‰¹å®šå­—ç¬¦ä¸²çš„è¡Œ
    cleaned_text = re.sub(r'//ğŸ§è£™ï¼š926953902', '', text)

    # æ›¿æ¢ç‰¹å®š URL
    cleaned_text = cleaned_text.replace(
        'https://github.moeyy.xyz/https://raw.githubusercontent.com/yoursmile66/TVBox/main/live.txt',
        'https://6851.kstore.space/zby.txt'
    )

    # æ›¿æ¢ "è±†ç“£â”ƒæœ¬æ¥å£å…è´¹-ğŸˆ²è´©å–" ä¸º "è±†ç“£TOPæ¦œ"
    cleaned_text = cleaned_text.replace('è±†ç“£â”ƒæœ¬æ¥å£å…è´¹-ğŸˆ²è´©å–', 'è±†ç“£TOPæ¦œ')

    # å¤„ç†"lives"ä¹‹å‰çš„éƒ¨åˆ†å†…å®¹
    if '"lives":' in cleaned_text:
        # è·å– "lives" ä¹‹å‰çš„æ‰€æœ‰å†…å®¹
        pre_lives_content = cleaned_text.split('"lives":')[0]

        # å®šä¹‰éœ€è¦åˆ é™¤çš„å…³é”®å­—åˆ—è¡¨
        keywords = ['è™ç‰™ç›´æ’­', 'æœ‰å£°å°è¯´å§', '88çœ‹çƒ', 'å°‘å„¿', 'å°å­¦', 'åˆä¸­', 'TgYunPan', 
                    'é«˜ä¸­', 'æ€¥æ•‘æ•™å­¦', 'æ˜“æœ', 'ç½‘ç›˜', 'çº¸æ¡', 'ï¼ˆå¢™å¤–ï¼‰', 'æœç´¢', 'æ˜“æœ', 'æœ¬åœ°', 'æ¨é€', 'åŠ¨æ¼«', 'åŠ¨æ¼«']

        # æ„å»ºæ­£åˆ™è¡¨è¾¾å¼ï¼Œåˆ é™¤åŒ…å«æŒ‡å®šå…³é”®å­—çš„ {} å—ï¼Œå¤„ç†è·¨è¡Œæƒ…å†µ
        for keyword in keywords:
            # ä½¿ç”¨ DOTALL æ¨¡å¼ (re.S)ï¼Œè®© `.` åŒ¹é…æ‰€æœ‰å­—ç¬¦ï¼ŒåŒ…æ‹¬æ¢è¡Œç¬¦
            pattern = r'\{[^{}]*' + re.escape(keyword) + r'[^{}]*\},?'
            pre_lives_content = re.sub(pattern, '', pre_lives_content, flags=re.S)

        # å°†å¤„ç†åçš„å†…å®¹ä¸ "lives" åé¢çš„éƒ¨åˆ†é‡æ–°æ‹¼æ¥
        post_lives_content = cleaned_text.split('"lives":', 1)[1]
        cleaned_text = pre_lives_content + '"lives":' + post_lives_content

    # æ‰“å°å¤„ç†åçš„æ–‡æœ¬
    print("\nå¤„ç†åçš„æ–‡æœ¬:")
    print(cleaned_text)

else:
    print("å“åº”å†…å®¹ä¸ºç©ºæˆ–çŠ¶æ€ç ä¸æ˜¯ 200")
