import requests
import json
import re

def fetch_and_clean_json(url):
    # å‘é€è¯·æ±‚è·å–å†…å®¹
    response = requests.get(url)
    response.raise_for_status()  # ç¡®ä¿è¯·æ±‚æˆåŠŸ

    # è·å–å†…å®¹å¹¶æŒ‰è¡Œåˆ†å‰²
    lines = response.text.splitlines()

    # åˆ é™¤æŒ‡å®šçš„æ³¨é‡Šè¡Œ
    cleaned_lines = [line for line in lines if line.strip() != "//ğŸ§è£™ï¼š926953902"]

    # åˆå¹¶å‰©ä½™è¡Œå¹¶è§£æä¸º JSON
    content = "\n".join(cleaned_lines)
    try:
        data = json.loads(content)
    except json.JSONDecodeError as e:
        print("JSON è§£æå¤±è´¥:", e)
        return None

    return data

def filter_and_replace_urls(data, keywords, new_url):
    if isinstance(data, dict):
        for key, value in list(data.items()):
            if key == "sites" or key == "lives":
                if isinstance(value, list):
                    # è¿‡æ»¤åˆ—è¡¨ä¸­çš„é¡¹
                    data[key] = [item for item in value if not contains_keywords(item, keywords)]
                    # æ›¿æ¢ URL
                    data[key] = [replace_urls(item, new_url) for item in data[key]]
            else:
                # é€’å½’å¤„ç†å­—å…¸ä¸­çš„å…¶ä»–é¡¹
                data[key] = filter_and_replace_urls(value, keywords, new_url)
    elif isinstance(data, list):
        data = [filter_and_replace_urls(item, keywords, new_url) for item in data]
    return data

def contains_keywords(item, keywords):
    if isinstance(item, str):
        return any(keyword in item for keyword in keywords)
    elif isinstance(item, dict):
        return any(contains_keywords(value, keywords) for value in item.values())
    elif isinstance(item, list):
        return any(contains_keywords(element, keywords) for element in item)
    return False

def replace_urls(item, new_url):
    if isinstance(item, str):
        # æ›¿æ¢ http æˆ– https çš„ URL
        return re.sub(r'https?://[^\s"]+', new_url, item)
    elif isinstance(item, dict):
        return {k: replace_urls(v, new_url) for k, v in item.items()}
    elif isinstance(item, list):
        return [replace_urls(element, new_url) for element in item]
    return item

# URL å’Œéœ€è¦åˆ é™¤çš„æ³¨é‡Šè¡Œæ•°
url = "https://mirror.ghproxy.com/https://raw.githubusercontent.com/yoursmile66/TVBox/main/XC.json"

# å…³é”®è¯åˆ—è¡¨
keywords = [
    "è™ç‰™ç›´æ’­", "æœ‰å£°å°è¯´å§", "88çœ‹çƒ", "å°‘å„¿", "å°å­¦", "åˆä¸­",
    "å¢™å¤–", "é«˜ä¸­", "æ€¥æ•‘æ•™å­¦", "æœ", "ç›˜"
]

# æ–°çš„ URL
new_url = "https://6851.kstore.space/zby.txt"

# å¤„ç† JSON æ•°æ®
data = fetch_and_clean_json(url)

if data is not None:
    filtered_and_updated_data = filter_and_replace_urls(data, keywords, new_url)
    print("å¤„ç†åçš„æ•°æ®ï¼š")
    print(json.dumps(filtered_and_updated_data, indent=2, ensure_ascii=False))
else:
    print("æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®")
