import requests
import json
import re
import hashlib


def fetch_remote_data(url):
    try:
        response = requests.get(url)
        print(f"å“åº”çŠ¶æ€ç : {response.status_code}")
        if response.status_code == 200 and response.text.strip():
            return response.text
        else:
            print("å“åº”å†…å®¹ä¸ºç©ºæˆ–çŠ¶æ€ç ä¸æ˜¯ 200")
            return None
    except requests.RequestException as e:
        print(f"è¯·æ±‚é”™è¯¯: {e}")
        return None


def clean_text(text):
    # åˆ é™¤ä»¥ // å¼€å¤´çš„æ³¨é‡Šè¡Œ
    text = re.sub(r'^\s*//.*\n?', '', text, flags=re.MULTILINE)

    # åŒ¹é…ä»¥ http æˆ– https å¼€å¤´çš„é“¾æ¥å¹¶æ›¿æ¢åŸŸå
    domain_pattern = r'https?://[^/]+/(https?://[\w./-]+)'
    return re.sub(domain_pattern, r'https://gh.999986.xyz/\1', text)


def process_json_data(cleaned_text):
    try:
        data = json.loads(cleaned_text)
        keys_to_remove = [
            'csp_Dm84', 'csp_Anime1', 'csp_Kugou', 'Aid', 'æ˜“æœ', 'csp_PanSearch', 'çŸ­è§†é¢‘', 'TgYunPan|æœ¬åœ°', 'csp_BookTing',
            'çº¸æ¡æœ', 'ç½‘ç›˜é›†åˆ', 'å°‘å„¿', 'åˆä¸­', 'é«˜ä¸­', 'å°å­¦', 'csp_Bili', '88çœ‹çƒ', 'csp_Qiyou', 'csp_Alllive', 'csp_Kanqiu',
            'æœ‰å£°å°è¯´å§', 'è™ç‰™ç›´æ’­', 'csp_Local', 'push_agent', 'TgYunPanLocal5', 'csp_FengGo', 'å¤šå¤š', 'MIUC', 'AList',
            'TgYunPanLocal4', 'TgYunPanLocal3', 'TgYunPanLocal2', 'TgYunPanLocal1', 'é…·å¥‡MV', 'æ–—é±¼ç›´æ’­', 'ç›˜Ta',
            'Youtube', 'ConfigCenter', 'JRKANç›´æ’­', 'æ˜Ÿå‰§ç¤¾', 'èœ¡ç¬”', 'ç©å¶gg', 'csp_YGP', 'csp_SP360', 'è‡³è‡»'
        ]

        # åˆ é™¤æŒ‡å®š key çš„é¡¹ï¼Œå¹¶å»æ‰ name ä¸­åŒ…å«â€œå¢™å¤–â€æˆ–â€œæœ¨å¶â€çš„é¡¹
        if 'sites' in data:
            data['sites'] = [
                site for site in data['sites']
                if site.get('key') not in keys_to_remove and 'å¢™å¤–' not in site.get('name', '') and 'æœ¨å¶' not in site.get('name', '')
            ]

            # ä¿®æ”¹æŒ‡å®š key çš„ name å­—æ®µ
            for site in data['sites']:
                if site.get('key') == 'csp_Douban':
                    site['name'] = 'ğŸ”è±†ç“£TOPæ¦œ'
                elif site.get('key') == 'csp_DouDou':
                    site['name'] = 'ğŸ”è±†ç“£TOPæ¦œ'
                elif site.get('key') == 'csp_Jianpian':
                    site['name'] = 'âš¡èç‰‡'
                elif site.get('key') == 'csp_SixV':
                    site['name'] = 'ğŸŒ¸æ–°6V'

            # å°† "csp_Jianpian" è°ƒæ•´åˆ°ç¬¬äºŒä¸ªä½ç½®
            jianpian_site = next((site for site in data['sites'] if site.get('key') == 'csp_Jianpian'), None)
            if jianpian_site:
                data['sites'].remove(jianpian_site)
                data['sites'].insert(1, jianpian_site)

        # æ›¿æ¢ "lives" åˆ—è¡¨ä¸­çš„æ•°æ®
        # ä¿ç•™ "lives" åˆ—è¡¨ä¸­çš„ç¬¬ä¸€ç»„æ•°æ®ï¼Œå¹¶åˆ é™¤å…¶ä»–æ•°æ®
        if 'lives' in data and len(data['lives']) > 0:
            # åˆ é™¤é™¤ç¬¬ä¸€ç»„å¤–çš„æ‰€æœ‰æ•°æ®
            data['lives'] = [data['lives'][0]]  # åªä¿ç•™ç¬¬ä¸€ç»„æ•°æ®

            # æ›¿æ¢ç¬¬ä¸€ç»„æ•°æ®çš„ name å’Œ url
            data['lives'][0]['name'] = 'IPTV4'
            data['lives'][0]['url'] = 'https://gh.999986.xyz/https://raw.githubusercontent.com/387673116/Tvbox/master/iptv4.m3u'

            # å¤åˆ¶ç¬¬ä¸€ç»„æ•°æ®ï¼Œä¿®æ”¹ç¬¬äºŒç»„å’Œç¬¬ä¸‰ç»„çš„æ•°æ®
            ipv6_data = {**data['lives'][0], 'name': 'IPTV6', 'url': 'https://gh.999986.xyz/https://raw.githubusercontent.com/387673116/Tvbox/master/iptv6.txt'}
            zonghe_data = {**data['lives'][0], 'name': 'ç»¼åˆ', 'url': 'https://gh.999986.xyz/https://raw.githubusercontent.com/387673116/Tvbox/master/zonghe.m3u'}

            # å°†ä¿®æ”¹åçš„æ•°æ®æ·»åŠ åˆ° "lives" åˆ—è¡¨
            data['lives'].append(ipv6_data)
            data['lives'].append(zonghe_data)

        return data

    except json.JSONDecodeError as e:
        print(f"JSON è§£æé”™è¯¯: {e}")
        return None


def save_to_json(data, filename):
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, separators=(',', ':'))
        print(f"å‹ç¼©åçš„ {filename} æ–‡ä»¶å·²ç”Ÿæˆ")
    except IOError as e:
        print(f"æ–‡ä»¶ä¿å­˜é”™è¯¯: {e}")


def compare_json_files(existing_file, new_data):
    try:
        # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œåˆ™è¯»å–å¹¶å¯¹æ¯”
        with open(existing_file, 'r', encoding='utf-8') as f:
            existing_data = json.load(f)

        # æ¯”è¾ƒä¸¤è€…çš„å†…å®¹æ˜¯å¦ç›¸åŒ
        existing_hash = hashlib.md5(json.dumps(existing_data, ensure_ascii=False).encode('utf-8')).hexdigest()
        new_hash = hashlib.md5(json.dumps(new_data, ensure_ascii=False).encode('utf-8')).hexdigest()

        return existing_hash != new_hash  # å¦‚æœå†…å®¹ä¸åŒï¼Œè¿”å› True

    except FileNotFoundError:
        return True  # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè®¤ä¸ºå†…å®¹ä¸åŒï¼Œéœ€è¦æ›´æ–°
    except Exception as e:
        print(f"æ–‡ä»¶å¯¹æ¯”æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False


if __name__ == "__main__":
    url = 'https://raw.githubusercontent.com/yoursmile66/TVBox/main/XC.json'
    raw_text = fetch_remote_data(url)

    if raw_text:
        cleaned_text = clean_text(raw_text)
        processed_data = process_json_data(cleaned_text)

        if processed_data:
            # æ£€æŸ¥å½“å‰ç›®å½•çš„ index.json æ˜¯å¦éœ€è¦æ›´æ–°
            if compare_json_files('index.json', processed_data):
                save_to_json(processed_data, 'index.json')
            else:
                print("index.json å†…å®¹æœªå˜åŒ–ï¼Œæœªè¿›è¡Œæ›´æ–°ã€‚")
