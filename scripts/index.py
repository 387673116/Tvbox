import requests
import json
import re

def fetch_remote_data(url):
    try:
        response = requests.get(url)
        print(f"å“åº”çŠ¶æ€ç : {response.status_code}")
        if response.status_code == 200 and response.text.strip():
            return response.text
        else:
            print("å“åº”å†…å®¹ä¸ºç©ºæˆ–çŠ¶æ€ç ä¸æ˜¯ 200")
            return None
    except requests.RequestException as e:
        print(f"è¯·æ±‚é”™è¯¯: {e}")
        return None

def clean_text(text):
    # åˆ é™¤ä»¥ // å¼€å¤´çš„æ³¨é‡Šè¡Œ
    text = re.sub(r'^\s*//.*\n?', '', text, flags=re.MULTILINE)

    # åŒ¹é…ä»¥ http æˆ– https å¼€å¤´çš„é“¾æ¥å¹¶æ›¿æ¢åŸŸå
    domain_pattern = r'https?://[^/]+/(https?://[\w./-]+)'
    return re.sub(domain_pattern, r'https://gh.999986.xyz/\1', text)

def process_json_data(cleaned_text):
    try:
        data = json.loads(cleaned_text)
        keys_to_remove = [
            'csp_Dm84', 'csp_Anime1', 'csp_Kugou', 'Aid', 'æ˜“æœ', 'csp_PanSearch', 'çŸ­è§†é¢‘', 'TgYunPan|æœ¬åœ°',
            'çº¸æ¡æœ', 'ç½‘ç›˜é›†åˆ', 'å°‘å„¿', 'åˆä¸­', 'é«˜ä¸­', 'å°å­¦', 'csp_Bili', '88çœ‹çƒ', 'csp_Qiyou', 'csp_Alllive', 
            'æœ‰å£°å°è¯´å§', 'è™ç‰™ç›´æ’­', 'csp_Local', 'push_agent', 'TgYunPanLocal5', 'csp_FengGo',
            'TgYunPanLocal4', 'TgYunPanLocal3', 'TgYunPanLocal2', 'TgYunPanLocal1', 'é…·å¥‡MV', 'æ–—é±¼ç›´æ’­',
            'Youtube', 'ConfigCenter', 'JRKANç›´æ’­', 'æ˜Ÿå‰§ç¤¾', 'èœ¡ç¬”', 'ç©å¶gg', 'csp_YGP', 'csp_SP360'
        ]
        
        # åˆ é™¤æŒ‡å®š key çš„é¡¹ï¼Œå¹¶å»æ‰ name ä¸­åŒ…å«â€œå¢™å¤–â€æˆ–â€œæœ¨å¶â€çš„é¡¹
        if 'sites' in data:
            data['sites'] = [
                site for site in data['sites'] 
                if site.get('key') not in keys_to_remove and 'å¢™å¤–' not in site.get('name', '') and 'æœ¨å¶' not in site.get('name', '')
            ]

            # ä¿®æ”¹æŒ‡å®š key çš„ name å­—æ®µ
            for site in data['sites']:
                if site.get('key') == 'csp_Douban':
                    site['name'] = 'ğŸ”è±†ç“£TOPæ¦œ'
                elif site.get('key') == 'csp_DouDou':
                    site['name'] = 'ğŸ”è±†ç“£TOPæ¦œ'
                elif site.get('key') == 'csp_Jianpian':
                    site['name'] = 'âš¡èç‰‡'
                elif site.get('key') == 'csp_SixV':
                    site['name'] = 'ğŸŒ¸æ–°6V'

            # å°† "csp_Jianpian" è°ƒæ•´åˆ°ç¬¬äºŒä¸ªä½ç½®
            jianpian_site = next((site for site in data['sites'] if site.get('key') == 'csp_Jianpian'), None)
            if jianpian_site:
                data['sites'].remove(jianpian_site)
                data['sites'].insert(1, jianpian_site)

        # æ›¿æ¢ "lives" åˆ—è¡¨ä¸­çš„ "url" å­—æ®µå€¼
        if 'lives' in data:
            for live in data['lives']:
                live['url'] = 'https://6851.kstore.space/zby.txt'

        return data

    except json.JSONDecodeError as e:
        print(f"JSON è§£æé”™è¯¯: {e}")
        return None

def save_to_json(data, filename):
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, separators=(',', ':'))
        print(f"å‹ç¼©åçš„ {filename} æ–‡ä»¶å·²ç”Ÿæˆ")
    except IOError as e:
        print(f"æ–‡ä»¶ä¿å­˜é”™è¯¯: {e}")

if __name__ == "__main__":
    url = 'https://raw.githubusercontent.com/yoursmile66/TVBox/main/XC.json'
    raw_text = fetch_remote_data(url)
    
    if raw_text:
        cleaned_text = clean_text(raw_text)
        processed_data = process_json_data(cleaned_text)
        
        if processed_data:
            save_to_json(processed_data, 'index.json')
